{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da581fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4499664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return np.array([item for sublist in t for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1918b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w,b,x): \n",
    "    return 1 / (1 + np.exp(-w*x+b) ) \n",
    "\n",
    "def update_rule(variable, result, rule):\n",
    "    \n",
    "\n",
    "    reward = -1\n",
    "    failure = 1\n",
    "    \n",
    "    if rule == 'stimulus':\n",
    "        \n",
    "        if result == True:\n",
    "            result_value = reward \n",
    "        \n",
    "        elif result == False:\n",
    "            result_value = failure\n",
    "            \n",
    "        variable += result_value \n",
    "    \n",
    "    elif rule == 'inference':\n",
    "        \n",
    "        if result == True:\n",
    "            result_value = reward \n",
    "            variable = 0\n",
    "            \n",
    "        elif result == False:\n",
    "            result_value = failure\n",
    "            variable += result_value\n",
    "            \n",
    "    return variable, result_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = #specify vluae\n",
    "bias = # specify value\n",
    "\n",
    "\n",
    "dataset_number = #specify value\n",
    "\n",
    "nBouts = 250\n",
    "\n",
    "bout = []\n",
    "\n",
    "noise_var = 0.0\n",
    "\n",
    "\n",
    "\n",
    "while len(bout) < nBouts:\n",
    "\n",
    "    pReward = 0.9\n",
    "    pSwitch = 0.3\n",
    "\n",
    "    switch = 0#False\n",
    "    move = False\n",
    "\n",
    "    reward = -1\n",
    "    failure = 1\n",
    "    variable = 0\n",
    "\n",
    "    myinputs = []\n",
    "    myvariable = [variable]\n",
    "\n",
    "    switch_result_check = [switch]\n",
    "    moving_probability = [0]\n",
    "\n",
    "    while not move:\n",
    "        result = np.random.binomial(1, pReward)\n",
    "        \n",
    "        variable, result_value = update_rule(variable, result, rule = 'stimulus') # 'stimulus' 'inference'\n",
    "\n",
    "        myinputs.append(result_value)\n",
    "        myvariable.append(variable)\n",
    "        \n",
    "        switch_result_check.append(switch)\n",
    "\n",
    "        if switch == False:\n",
    "            switch = np.random.binomial(1,pSwitch)\n",
    "        elif switch == True:\n",
    "            pReward = 0\n",
    "\n",
    "        pMove = sigmoid(weight,bias, variable)\n",
    "        moving_probability.append(pMove)\n",
    "\n",
    "        move = np.random.binomial(1, pMove)\n",
    "        \n",
    "        if move == True:\n",
    "            break\n",
    "\n",
    "    if len(myinputs) >= 1:\n",
    "        bout.append([myvariable, myinputs ,switch_result_check, moving_probability])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57301d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we will attempt to divide the test/train data per bout vs\n",
    "randomly sampling from the entire dataset\n",
    "\"\"\"\n",
    "\n",
    "percentTestBouts = 0.1\n",
    "\n",
    "numBouts = int(nBouts*percentTestBouts)\n",
    "\n",
    "testBoutsIdx = [random.randint(0, nBouts-1) for i in range(numBouts)]\n",
    "\n",
    "#variable = bout[boutNumber][0]\n",
    "mouse_variable = []\n",
    "mouse_state = []\n",
    "\n",
    "for boutNumber in range(nBouts):\n",
    "    state = np.zeros(len(bout[boutNumber][0]))\n",
    "    state[-1] = 1\n",
    "    \n",
    "    mouse_state.append(state)\n",
    "    mouse_variable.append(bout[boutNumber][0])\n",
    "    \n",
    "flatten_variable = flatten(mouse_variable)\n",
    "flatten_state = flatten(mouse_state)\n",
    "\n",
    "mouse_variable_np = np.array(mouse_variable)\n",
    "mouse_state_np = np.array(mouse_state)\n",
    "\n",
    "x_test = mouse_variable_np[testBoutsIdx]\n",
    "y_test = mouse_state_np[testBoutsIdx]\n",
    "\n",
    "x_test,y_test = flatten(x_test) , flatten(y_test)\n",
    "\n",
    "x_train = np.delete(mouse_variable_np,testBoutsIdx)\n",
    "y_train = np.delete(mouse_state_np,testBoutsIdx)\n",
    "\n",
    "x_train,y_train = flatten(x_train),flatten(y_train)\n",
    "\n",
    "x_train = x_train.reshape((-1,1))\n",
    "x_test = x_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "# model.fit(x_train.reshape((-1,1)), y_train)\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca423876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict(x_test)\n",
    "test_accuracy = model.score(x_test, y_test)\n",
    "\n",
    "weight_predict = (model.coef_).flatten()\n",
    "bias_predict = -(model.intercept_).flatten()\n",
    "probs = model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (15,8))\n",
    "\n",
    "x_min = -50\n",
    "x_max = -x_min\n",
    "x_axis = np.arange(x_min,x_max,0.1)\n",
    "\n",
    "plt.plot(x_test,y_test, '.',alpha = 0.4,markersize=12, color = 'blue', label = 'Binary Decisions')\n",
    "plt.plot(x_test,probs.T[1,:], 'x',alpha = 0.4,markersize=12, color = 'red', label = 'Predicted Probabilities')\n",
    "\n",
    "plt.plot(x_axis, sigmoid(weight,bias,x_axis), linewidth = 5, color = 'green', label = 'Original Sigmoid Function')\n",
    "plt.plot(x_axis, sigmoid(weight_predict,bias_predict,x_axis), '-.' , linewidth = 2,color = 'orange', label = 'Predicted Sigmoid Function')\n",
    "\n",
    "plt.text(-53, 0.6, f'$\\eta = \\omega x + b +\\epsilon$\\n$\\omega_p = ${np.round(weight_predict[0],2)}\\n$b_p = ${np.round(bias_predict[0],2)}', fontsize = 17)\n",
    "\n",
    "plt.text(-53, 0.5, f'Model Accuracy: {np.round(test_accuracy*100,2)} %', fontsize = 17)\n",
    "\n",
    "\n",
    "plt.legend( fontsize = 15)\n",
    "\n",
    "plt.title(f'Stimulus Strategy\\n$\\omega = ${np.round(weight,2)} $b = ${np.round(bias,2)}', fontsize = 25)\n",
    "\n",
    "plt.xlabel('Value Parameter',  fontsize = 20)\n",
    "plt.ylabel('Move Probability',  fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cbcd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "export_data = [[x_train,y_train],[x_test,y_test]]\n",
    "\n",
    "export_path = \"./data/\"+ str(dataset_number) +\"/\"\n",
    "if not os.path.exists(export_path):\n",
    "    os.makedirs(export_path)\n",
    "\n",
    "export_filename = \"data\"\n",
    "outfile = open(export_path+export_filename,'wb')\n",
    "pickle.dump(export_data,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49298c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
